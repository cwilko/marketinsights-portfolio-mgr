{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market data refresh \n",
    "\n",
    "### Input Description\n",
    "\n",
    "RAW OHLC data.\n",
    "\n",
    "### Output  \n",
    "\n",
    "Clean OHLC data in a hdf store\n",
    "\n",
    "### Operations\n",
    "\n",
    "This code takes a financial market data file and runs it through a processing pipeline. The following operations are carried out :\n",
    "\n",
    "- Localise the time data to market time\n",
    "- Merge with existing RAW data based on datetime\n",
    "- Save the resulting RAW data to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade \"../../quantutils\"\n",
    "import json, os, pandas\n",
    "import quantutils.dataset.pipeline as ppl\n",
    "from quantutils.api.datasource import MarketDataStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def refreshMarketData(mds, root, datasource_file):\n",
    "\n",
    "    # Loop over datasources...\n",
    "    # TODO: In chronological order\n",
    "\n",
    "    datasources = json.load(open(root + \"/\" + datasource_file))\n",
    "    \n",
    "    for datasource in datasources:\n",
    "\n",
    "        DS_path = root + \"/\" + datasource[\"name\"] + \"/\"\n",
    "        SRC_path = DS_path + \"raw/\"\n",
    "\n",
    "        for market in datasource[\"markets\"]:\n",
    "\n",
    "            for source in market[\"sources\"]:\n",
    "\n",
    "                # Loop over any source files...\n",
    "                for infile in os.listdir(SRC_path):\n",
    "\n",
    "                    if infile.lower().startswith(source[\"name\"].lower()):\n",
    "\n",
    "                        print(\"Adding \" + infile + \" to \" + market[\"name\"] + \" table\")\n",
    "\n",
    "                        # Load RAW data (assume CSV)\n",
    "                        newData = pandas.read_csv(SRC_path + infile,\n",
    "                                                  index_col=datasource[\"index_col\"],\n",
    "                                                  parse_dates=datasource[\"parse_dates\"],\n",
    "                                                  header=None,\n",
    "                                                  names=[\"Date\", \"Time\", \"Open\", \"High\", \"Low\", \"Close\"],\n",
    "                                                  usecols=range(0, 6),\n",
    "                                                  skiprows=datasource[\"skiprows\"],\n",
    "                                                  dayfirst=datasource[\"dayfirst\"]\n",
    "                                                  )\n",
    "\n",
    "                        if newData is not None:\n",
    "\n",
    "                            newData = ppl.localize(newData, datasource[\"timezone\"], \"UTC\")\n",
    "\n",
    "                            mds.append(source[\"name\"], newData, source[\"sample_unit\"], update=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding D&J-IND_150101_170519.csv to DOW table\n",
      "Converting from US/Eastern to UTC\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/D&J-IND?unit=5min\n",
      "<Response [200]>\n",
      "{\"rc\":\"success\"}\n",
      "\n",
      "{'rc': 'success'}\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/D&J-IND?unit=5min\n",
      "{'rc': 'success'}\n",
      "Adding D&J-IND_161003_180319.csv to DOW table\n",
      "Converting from US/Eastern to UTC\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/D&J-IND?unit=5min\n",
      "<Response [200]>\n",
      "{\"rc\":\"success\"}\n",
      "\n",
      "{'rc': 'success'}\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/D&J-IND?unit=5min\n",
      "{'rc': 'success'}\n",
      "Adding D&J-IND_130101_141231.csv to DOW table\n",
      "Converting from US/Eastern to UTC\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/D&J-IND?unit=5min\n",
      "<Response [200]>\n",
      "{\"rc\":\"success\"}\n",
      "\n",
      "{'rc': 'success'}\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/D&J-IND?unit=5min\n",
      "{'rc': 'success'}\n",
      "Adding SANDP-500_161003_180319.csv to SPY table\n",
      "Converting from US/Eastern to UTC\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/SANDP-500?unit=5min\n",
      "<Response [200]>\n",
      "{\"rc\":\"success\"}\n",
      "\n",
      "{'rc': 'success'}\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/SANDP-500?unit=5min\n",
      "{'rc': 'success'}\n",
      "Adding SANDP-500_150101_170519.csv to SPY table\n",
      "Converting from US/Eastern to UTC\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/SANDP-500?unit=5min\n",
      "<Response [200]>\n",
      "{\"rc\":\"success\"}\n",
      "\n",
      "{'rc': 'success'}\n",
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/SANDP-500?unit=5min\n",
      "{'rc': 'success'}\n",
      "Adding SANDP-500_130101_141231.csv to SPY table\n",
      "Converting from US/Eastern to UTC\n"
     ]
    }
   ],
   "source": [
    "mds = MarketDataStore(remote=True, location=\"http://pricestore.192.168.1.203.nip.io\")\n",
    "refreshMarketData(mds, \"../datasources\", \"datasources_finam.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rc': 'success'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mds.delete(\"D&J-IND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text\n"
     ]
    }
   ],
   "source": [
    "print('Your text', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding WallSt-hourly-120217.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Appending data...\n",
      "Adding WallSt-hourly-011116.txt to DOW table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:155: NaturalNameWarning: object name is not a valid Python identifier: 'WallSt-hourly'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-210618.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Appending data...\n",
      "Adding WallSt-hourly-230718.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Appending data...\n",
      "Adding WallSt-hourly-050517.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-140518.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-040417.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-030818.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-160517.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-091116.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-230617.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-200317.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-200318.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-061116.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-050617.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-180418.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-301016.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-021116.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-040618.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding WallSt-hourly-071116.txt to DOW table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-230617.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Appending data...\n",
      "Adding SP500-hourly-040417.txt to SPY table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:155: NaturalNameWarning: object name is not a valid Python identifier: 'SP500-hourly'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-210618.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Appending data...\n",
      "Adding SP500-hourly-200318.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-180418.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-140518.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-040618.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-030818.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Appending data...\n",
      "Adding SP500-hourly-230718.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-050517.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding SP500-hourly-050617.txt to SPY table\n",
      "Converting from Europe/London to UTC\n",
      "Resampling to H periods\n",
      "Re-writing table data for update...\n",
      "Adding D&J-IND_150101_170519.csv to DOW table\n",
      "Converting from US/Eastern to UTC\n",
      "Resampling to 5min periods\n",
      "Appending data...\n",
      "Adding D&J-IND_161003_180319.csv to DOW table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:155: NaturalNameWarning: object name is not a valid Python identifier: 'D&J-IND'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from US/Eastern to UTC\n",
      "Resampling to 5min periods\n",
      "Re-writing table data for update...\n",
      "Adding D&J-IND_130101_141231.csv to DOW table\n",
      "Converting from US/Eastern to UTC\n",
      "Resampling to 5min periods\n",
      "Re-writing table data for update...\n",
      "Adding SANDP-500_161003_180319.csv to SPY table\n",
      "Converting from US/Eastern to UTC\n",
      "Resampling to 5min periods\n",
      "Appending data...\n",
      "Adding SANDP-500_150101_170519.csv to SPY table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:155: NaturalNameWarning: object name is not a valid Python identifier: 'SANDP-500'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from US/Eastern to UTC\n",
      "Resampling to 5min periods\n",
      "Re-writing table data for update...\n",
      "Adding SANDP-500_130101_141231.csv to SPY table\n",
      "Converting from US/Eastern to UTC\n",
      "Resampling to 5min periods\n",
      "Re-writing table data for update...\n"
     ]
    }
   ],
   "source": [
    "mds = MarketDataStore(location=\"../datasources\")\n",
    "refreshMarketData(mds, \"../datasources\", \"datasources.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MarketDataStore(remote=True, location=\"http://pricestore.192.168.1.203.nip.io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://pricestore.192.168.1.203.nip.io/prices/datasource/D%26J-IND\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = mds.get(\"D%26J-IND\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-04 15:00:00</th>\n",
       "      <td>13407.46</td>\n",
       "      <td>13411.91</td>\n",
       "      <td>13377.22</td>\n",
       "      <td>13387.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04 16:00:00</th>\n",
       "      <td>13387.37</td>\n",
       "      <td>13420.86</td>\n",
       "      <td>13386.80</td>\n",
       "      <td>13408.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04 17:00:00</th>\n",
       "      <td>13408.20</td>\n",
       "      <td>13415.80</td>\n",
       "      <td>13403.52</td>\n",
       "      <td>13405.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low     Close\n",
       "2013-01-04 15:00:00  13407.46  13411.91  13377.22  13387.45\n",
       "2013-01-04 16:00:00  13387.37  13420.86  13386.80  13408.33\n",
       "2013-01-04 17:00:00  13408.20  13415.80  13403.52  13405.06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/prices/datasource/D%26J-IND?unit=H\n",
      "<Response [500]>\n",
      "http://localhost:8080/prices/datasource/D%26J-IND?unit=H\n",
      "{'message': 'Internal Server Error'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Internal Server Error'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mds.append(\"D%26J-IND\", x, \"H\", update=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MarketDataStore(remote=True, location=\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "data = x.to_json(orient='split', date_format=\"iso\")\n",
    "data2 = {\"columns\":[\"Open\",\"High\",\"Low\",\"Close\"],\"index\":[\"2013-01-04T15:00:00.000Z\",\"2013-01-04T16:00:00.000Z\",\"2013-01-04T17:00:00.000Z\"],\"data\":[[13407.46,13411.91,13377.22,13387.45],[13387.37,13420.86,13386.8,13408.33],[13408.2,13415.8,13403.52,13405.06]]}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "url=\"http://pricestore.192.168.1.203.nip.io/prices/datasource/D%26J-IND?unit=H\"\n",
    "r = requests.post(url=url, headers=headers, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': 'Error: Entry already exists for data starting at index 2013-01-04 15:00:00+00:00',\n",
       " 'rc': 'fail'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\": [\"Open\", \"High\", \"Low\", \"Close\"], \"index\": [\"2013-01-04T15:00:00.000Z\", \"2013-01-04T16:00:00.000Z\", \"2013-01-04T17:00:00.000Z\"], \"data\": [[13407.46, 13411.91, 13377.22, 13387.45], [13387.37, 13420.86, 13386.8, 13408.33], [13408.2, 13415.8, 13403.52, 13405.06]]}'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(json.loads(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\":[\"Open\",\"High\",\"Low\",\"Close\"],\"index\":[\"2013-01-04T15:00:00.000Z\",\"2013-01-04T16:00:00.000Z\",\"2013-01-04T17:00:00.000Z\"],\"data\":[[13407.46,13411.91,13377.22,13387.45],[13387.37,13420.86,13386.8,13408.33],[13408.2,13415.8,13403.52,13405.06]]}'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
